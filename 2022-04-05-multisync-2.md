---
layout: page
title: "Draft - Adding multiple syncobjs support for V3D(V) (Part 2)"
date: 2022-04-05 07:00:00 -0300
draft: draft
permalink: /draft-multisync-p2
---

In the previous post, I described how we enable multiple syncobjs capabilities in the V3D kernel driver.
Now I will tell you what was changed on the userspace side, where we reworked the V3DV sync mechanisms to use Vulkan multiple wait and signal semaphores directly.
This change represents greater adherence to the Vulkan submission framework.

I was not used to Vulkan concepts and V3DV driver, but I counted on the guidance
of the Igalia's Graphics team, mainly [Iago Toral](https://blogs.igalia.com/itoral) (thanks!) to understand the [Vulkan Graphics Pipeline](https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics/Introduction), [sync scopes](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.html#synchronization-dependencies-scopes) and [submission order](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.html#synchronization-submission-order). Therefore, we had to change the original V3DV implementation of [vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html) and all related functions to allow direct mapping of multiple semaphores from V3DV to the V3D-kernel interface.

*Disclaimer:* Here's a brief and probably inaccurate background, which we'll go into more detail later on.

In Vulkan, GPU work submissions are described as command buffers.
These command buffers, with GPU jobs, are grouped in a command buffer
submission batch, specified by [vkSubmitInfo](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkSubmitInfo.html), and submitted to a queue for execution.
[vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html) is the command called to submit command buffers to a queue.
Besides command buffers, vkSubmitInfo also specifies semaphores to wait before executing the command buffer batch and to be signaled when all command buffers in the batch complete.
When all command buffer batches have completed execution, a fence can be signaled too.

From this sequence, we can see some [implicit ordering guarantees](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.html#synchronization-implicit).
Submission order defines the start order of execution between command buffers, in other words, the beginning of a execution is defined by the order in which pSubmits appear in VkQueueSubmit and pCommandBuffers appear in VkSubmitInfo. However, we don't have any completion guarantees, that means, they may overlap and complete out of order. Except for jobs submitted to the same GPU queue, since it is only possible to execute a job when its GPU engine completed the execution of the previous one. For signal operation order, a fence is ordered after all semaphores signal operations. In addition to implicit sync, we have also some resources for explicit sync, such as semaphores, fences and events. 

Bearing in mind these implicit and explicit sync mechanisms, we rework the V3DV implementation of queue submissions to better use multiple syncobjs capabilities from the kernel. 
You can find this work in this merge request:
[v3dv: add support to multiple wait and signal
semaphores](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/13178).
In this blog post, we run through each scope of change of this merge request
for a V3D driver-guided description of the multisync support implementation.

#### Groundwork and basic code clean-up:

As the original v3d-kernel interface allowed only one semaphore, V3DV
resorted to booleans to "translate" multiple semaphores into one. As a
consequence, if a command buffer batch had at least one semaphore, it
needed to wait on all jobs submitted complete before starts its
execution. So, we created and changed structs that store semaphores
information to accept the actual list of wait semaphores, instead of
just boolean.

- v3dv: drop unused variable on handle\_set\_event\_cpu\_job
- v3dv: wrap wait semaphores info in v3dv\_submit\_info\_semaphores
- v3dv: store wait semaphores in event\_wait\_cpu\_job\_info

#### Expose multisync kernel interface to the driver:

In this two commits below, we basically updated the
[DRM V3D interface](https://cgit.freedesktop.org/drm/drm-misc/tree/include/uapi/drm/v3d_drm.h)
from that one defined in the kernel and verify if the multisync capability
is available for use.

- drm-uapi/v3d: extend interface for multiple semaphores support
- v3dv: check multiple semaphores capability

#### Handle multiple semaphores for all GPU job types:

At this point, we were only changing the submission design to consider multiple wait
semaphores. Before supporting multisync, v3dv were waiting for the last job submitted
being signalled when at least one wait semaphore was defined, even when
serialization wasn't required. In v3dv, we distinguish three types of GPU job according
to the GPU queue in which they are submitted:
* Control List (CL) for binning and rendering
* Texture Formatting Unit (TFU)
* Compute Shader Dispatch (CSD)

Therefore, we changed their submission setup to make jobs submitted to any
GPU queues able to handle more than one wait semaphores.

- v3dv: enable multiple semaphores on cl submission
- v3dv: enable multiple semaphores for tfu job
- v3dv: enable multiple semaphores for csd job
- v3dv: enable GPU jobs to signal multiple semaphores

These commits created all mechanisms to set arrays of wait and signal
semaphores for GPU job submissions: checking the conditions to define the wait\_stage,
wrapping them in a multisync extension and configuring the generic extension
as a multisync extension, according to the kernel interface (described in the [previous blog post](/draft-multisync-p1)).

Finally, we extended the ability of GPU jobs to handle multiple signal semaphores,
but at this point no GPU job is actually in charge of signalling them. With this
in place, we could rework part of the code that track CPU and GPU job completions by
verifying the GPU status and also threads spawned by Event jobs.

#### Rework the QueueWaitIdle mechanism to track the syncobj of the last job submitted in each queue:

As we had only single in/out syncobj interfaces for semaphores, we used a
single `last_job_sync` to syncronize job dependencies of previous submission.
Although in the kernel space the DRM scheduler guarantees the order of starting
to execute a job in the same queue, the order of completion isn't predictable. On
the other hand, we still need to use syncobjs to follow job completion, since
we have events threads in the CPU side. Therefore, a more accurate
implementation requires `last_job` syncobjs to track when each engine (CL, TFU
and CSD) is idle. We also needed to keep the driver working on previous versions
of v3d kernel-driver with single semaphores, then we keep tracking an ANY
`last_job_sync` to preserve the previous implementation. 

- v3dv: track submitted jobs by GPU queue type

#### Rework synchronization and submission design to let the jobs handle wait and signal semaphores:

With multiple semaphores support, the conditions for waiting and signalling
semaphores changed accordingly to particularities of each GPU job (CL, CSD,
TFU) and also CPU job restrictions (Events, CSD indirect,
etc.). In this sense, we redesigned V3DV semaphores handling and job
submissions for command buffer batches in
[vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html).

We scrutinised possible scenarios on submitting command buffer batches, to
carefully change the original implementation. It resulted in three commits
more:

- v3dv: handle wait semaphores in the first job by queue

For each command buffer, we keep track of whether we have submitted a job to
each GPU queue (CSD, TFU, CL) and a CPU job. For this, we use syncobjs to track
the last job submitted to each GPU queue and a flag that indicates if this
represents the beginning of a command buffer.

The first GPU job submitted to a GPU queue in a command buffer should wait on
wait semaphores. The first CPU job submitted in a command buffer should call
v3dv\_QueueWaitIdle() to do the waiting and ignore semaphores (because it is
waiting for everything).

If the job is not the first, but has the serialize flag set, it should wait on
the completion of all last job submitted to any GPU queue before running. In
practice, it means using syncobjs to track the last job submitted by queue and
add these syncobjs as job dependencies of this serialized job.

- v3dv: process signal semaphores in the very last job

If this job is the last job of a command buffer batch, it may be used to signal
semaphores if this command buffer batch has only one type of GPU job (because
we have guarantees of execution ordering). Otherwise, we emit a no-op job just
to signal semaphores. It waits on completion of all last job submitted to any
GPU queue and then signal semaphores. *Note: at some point, we changed this
approach to correctly deal with ordering changes caused by event threads.
Whenever we have a event job in the command buffer, we cannot use the last job
in the last command buffer. We have to wait all event threads complete to
signal*

- v3dv: signal fence when all submitted jobs complete execution

After submitting all command buffers, we emit a no-op job that wait on all last
jobs by queue completion and signal fence. *Note: at some point, we changed
this approach to correct deal with ordering changes caused by event threads, as
mentioned before.

### Additional fixes and improvements for multisync implementation

With many changes and many rounds of reviews, the patchset was merged. After
more validations and code review, we polished and fixed the implementation
together with external contributions:
- v3dv: fix double free error when releasing `sems_info` resources
- v3dv: enable multisync in the simulator
- v3dv: Add missing unlocks on errors.
- v3dv: don't submit noop job if there is nothing to wait on or signal
- v3dv: fix temporary imports of semaphores and fences with multisync
- v3dv: don't signal semaphores/fences from a wait thread
- v3dv: fix semaphore wait from CPU job
- v3dv: Stop leaking in/out fences with multisync

Also, multiple semaphores capabilities enable v3dv to add new features and switch
to the common sychronization and submission framework:

- [v3dv: expose support for semaphore imports](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/15342)
> This was waiting for multisync support in the v3d kernel, which is already available. Exposing this feature however enabled a few more CTS tests that exposed pre-existing bugs in the user-space driver so we fix those here before exposing the feature.

- [v3dv: Switch to the common submit framework](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/15704)
> This should give you emulated timeline semaphores for free and kernel-assisted sharable timeline semaphores for cheap once you have the kernel interface wired in.

### Final considerations

We used a set of games to ensure no performance regression in the new implementation.
We reproduced scenes we have recorded with
[GFXReconstruct](https://github.com/LunarG/gfxreconstruct). We didn't noticed any performance compromise, and we have analyzed reasons for performance boost when reproducing vkQuake.
