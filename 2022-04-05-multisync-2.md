---
layout: page
title: "Draft - Adding multiple syncobjs support for V3D(V) (Part 2)"
date: 2022-04-05 07:00:00 -0300
draft: draft
permalink: /draft-multisync-p2
---

In the previous post, I described how we enable multiple syncobjs capabilities in the V3D kernel driver.
Now I will tell you what was changed on the userspace side, where we reworked the V3DV sync mechanisms to use Vulkan multiple wait and signal semaphores directly.
This change represents greater adherence to the Vulkan submission framework.

I was not used to Vulkan concepts and V3DV driver, but I counted on the guidance
of the Igalia's Graphics team, mainly [Iago Toral](https://blogs.igalia.com/itoral) (thanks!) to understand the [Vulkan Graphics Pipeline](https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics/Introduction), [sync scopes](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.html#synchronization-dependencies-scopes) and [submission order](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/vkspec.html#synchronization-submission-order). Therefore, we had to change the original V3DV implementation of [vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html) and all related functions to allow direct mapping of multiple semaphores from V3DV to the V3D-kernel interface.

*Disclaimer:* Here's a brief and probably inaccurate background, which we'll go into more detail later on.

In Vulkan, GPU work submissions are described as command buffers.
These command buffers, with GPU jobs, are grouped in a command buffer
submission batch, specified by [vkSubmitInfo](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkSubmitInfo.html), and submitted to a queue for execution.
[vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html) is the command called to submit command buffers to a queue.
Besides GPU commands, vkSubmitInfo also specifies semaphores to wait before executing the command buffer batch and to be signaled when all command buffers in the batch complete.
When all command buffer batches have completed execution, a fence can be signaled.

From this sequence, we can see some implicit ordering guarantees.
Submission order defines the start execution other between command buffers, that means the begin execution order is defined by the order in which pSubmits appear in VkQueueSubmit and pCommandBuffers appear in VkSubmitInfo. However, we don't have any completion guarantees, that means, they may overlap and complete out of order.
For signal operation order, a fence is ordered after all semaphores signal operations. In addition to implicit sync, we have also some resources for explicit sync, such as semaphores, fences and events. Bearing in mind these implicit and explicit sync mechanisms, we rework the V3DV implementation of queue submissions to better use multiple syncobjs capabilities from the kernel. 


You can find this work at:
[v3dv: add support to multiple wait and signal
semaphores](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/13178).
Next, we run through each commit to technically contextualize each scope of change. 

#### Groundwork and code clean-up:

- v3dv: drop unused variable on handle\_set\_event\_cpu\_job
- v3dv: wrap wait semaphores info in v3dv\_submit\_info\_semaphores
- v3dv: store wait semaphores in event\_wait\_cpu\_job\_info

As the original v3d-kernel interface allowed only one semaphore, V3DV
resorted to booleans to "reduce" multiple semaphores into one. So, if a
command buffer batch had at least one semaphore, it needed to wait on
everything before starts execution. So, in these commits we switched
the structure to accept the actual list of wait semaphores, instead of
just boolean.

#### Expose multisync kernel interface to the driver:
- drm-uapi/v3d: extend interface for multiple semaphores support
- v3dv: check multiple semaphores capability

Basically, they imported the [DRM V3D interface](https://cgit.freedesktop.org/drm/drm-misc/tree/include/uapi/drm/v3d_drm.h) defined in the kernel and verify if
the multisync capability is available for use.

#### Handle multiple wait semaphores for all GPU job types:
- v3dv: enable multiple semaphores on cl submission
- v3dv: enable multiple semaphores for tfu job
- v3dv: enable multiple semaphores for csd job


Created all mechanisms to set arrays of wait and signal semaphores, check the
conditions that define the wait\_stage and wrap them in a multisync extension.
Also passes multisync extension via generic extension to the kernel driver. At
this point we are only changing the submission design to consider multiple wait
semaphores. Before supporting multisync, v3dv waits for the last job submitted
being signalled when at least one wait semaphore was defined, even when
serialization wasn't required. After these changes, jobs to any submission
queues handle actual wait semaphores. Next, we enable the use of multiple
signal semaphores too.

#### Handle multiple signal semaphores
- v3dv: enable GPU jobs to signal multiple semaphores

It extends the ability of GPU jobs to handle multiple signal semaphores, but at
this point no GPU job is actually in charge of signalling them. With this place,
we could rework part of the code that track CPU and GPU job completions. It
envolves verifying the GPU status and also threads spawned by Event jobs.

#### Rework the QueueWaitIdle mechanism to track the syncobj of the last job submitted in each queue.
- v3dv: track submitted jobs by GPU queue type

As we had only single in/out syncobj interfaces for semaphores, we used a
single `last_job_sync` to syncronize job dependencies of previous submission.
Although in the kernel space the DRM scheduler guarantees the order to start to
execute a job in the same queue, the order of completion isn't predictable. On
the other hand, we still need to use syncobjs to follow job completion, since
we have events threads in the CPU side. Therefore, a more accurate
implementation requires `last_job` syncobjs for each engine: CL, TFU and CSD. We
also needed to keep the driver working on previous versions of v3d
kernel-driver with single semaphores, then we keep tracking an ANY
`last_job_sync` to preserve the previous implementation. 

#### Rework synchronization and submission design to let the jobs handle wait and signal semaphores.

With multiple semaphores support, the conditions for waiting and signalling
semaphores changed accordingly to characteristics of each GPU job (CL, CSD,
TFU) and also CPU job peculiarities and restrictions (Events, CSD indirect,
etc.). In this sense, we redesigned V3DV semaphores handling and job
submissions for command buffer batches in
[vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html).

We scrutinised possible scenarios on submitting command buffer batches, to
carefully change the original implementation. It resulted in three commits
more:

- v3dv: handle wait semaphores in the first job by queue

For each command buffer, we keep track of whether we have submitted a job to
each GPU queue (CSD, TFU, CL) and a CPU job. For this, we use syncobjs to track
the last job submitted to each GPU queue and a flag that indicates if this
represents the beginning of a command buffer.

The first GPU job submitted to a GPU queue in a command buffer should wait on
wait semaphores. The first CPU job submitted in a command buffer should call
v3dv\_QueueWaitIdle() to do the waiting and ignore semaphores (because it is
waiting for everything).

If the job is not the first, but has the serialize flag set, it should wait on
the completion of all last job submitted to any GPU queue before running. In
practice, it means using syncobjs to track the last job submitted by queue and
add these syncobjs as job dependencies of this serialized job.

- v3dv: process signal semaphores in the very last job

If this job is the last job of a command buffer batch, it may be used to signal
semaphores if this command buffer batch has only one type of GPU job (because
we have guarantees of execution ordering). Otherwise, we emit a no-op job just
to signal semaphores. It waits on completion of all last job submitted to any
GPU queue and then signal semaphores. *Note: at some point, we changed this
approach to correctly deal with ordering changes caused by event threads.
Whenever we have a event job in the command buffer, we cannot use the last job
in the last command buffer. We have to wait all event threads complete to
signal*

- v3dv: signal fence when all submitted jobs complete execution

After submitting all command buffers, we emit a no-op job that wait on all last
jobs by queue completion and signal fence. *Note: at some point, we changed
this approach to correct deal with ordering changes caused by event threads, as
mentioned before.*

### Additional fixes and improvements for multisync implementation

With many changes and many rounds of reviews, the patchset was merged. After
more validations and code review, we polished and fixed the implementation
together with external contributions:
- v3dv: fix double free error when releasing `sems_info` resources
- v3dv: enable multisync in the simulator
- v3dv: Add missing unlocks on errors.
- v3dv: don't submit noop job if there is nothing to wait on or signal
- v3dv: fix temporary imports of semaphores and fences with multisync
- v3dv: don't signal semaphores/fences from a wait thread
- v3dv: fix semaphore wait from CPU job
- v3dv: Stop leaking in/out fences with multisync

Also, Iago Toral and Alejandro PiÃ±eiro have been working on implementing new
features that depended on multisync capabilities:

- [v3dv: expose support for semaphore imports](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/15342)
> This was waiting for multisync support in the v3d kernel, which is already available. Exposing this feature however enabled a few more CTS tests that exposed pre-existing bugs in the user-space driver so we fix those here before exposing the feature.

- [v3dv: Port to the common synchronization and submit framework - WIP](https://gitlab.freedesktop.org/mesa/mesa/-/issues/5638)
> This should give you emulated timeline semaphores for free and kernel-assisted sharable timeline semaphores for cheap once you have the kernel interface wired in.

### Final considerations

We use a set of games to ensure new implementation doesn't cause regressions.
For performance assesment, we reproduced scenes we have recorded with
[GFXReconstruct](https://github.com/LunarG/gfxreconstruct). In general, we
didn't see any significant change on performance, neither for better nor for
worse, but vkQuake showed an improvement of ~15% from our recordings. 
