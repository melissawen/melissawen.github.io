---
layout: page
title: "Draft - Adding multiple syncobjs support for V3D(V) (Part 2)"
date: 2022-04-05 07:00:00 -0300
draft: draft
permalink: /draft-multisync-p2
---

With multisync support in V3D kernel-driver, we were able to rework
synchronization mechanisms on V3DV to directly use multiple wait and signal
semaphores. These changed many points of queue submissions in the Vulkan
driver, but brought accuracy to the implementation of synchronizing mechansims
in the driver.

I was not used to Vulkan concepts and V3DV driver, but with the guidance of my
team, mainly [Iago Toral](https://blogs.igalia.com/itoral) (thanks!), we
enabled multiple semaphores on job submissions. You can find this work at:
[v3dv: add support to multiple wait and signal
semaphores](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/13178).
Next, we run through each commit to describe a bit more this implementation by
scope of change. 

#### Groundwork to pass multiple semaphores in case of a command buffer batch with CPU-events jobs:

- v3dv: drop unused variable on handle\_set\_event\_cpu\_job
- v3dv: wrap wait semaphores info in v3dv\_submit\_info\_semaphores
- v3dv: store wait semaphores in event\_wait\_cpu\_job\_info

We were switching our job submission design from verifying `at least one
semaphore` to using `all wait and signal semaphores`. As a groundwork, we
needed to enable CPU-Event threads using wait and signal semaphores info
defined by
[vkSubmitInfo](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/VkSubmitInfo.html)
when continuing job submissions after the waiting event completes. These three
commits made it possible by creating an struct that wraps semaphores info and
stores it in wait-event info.

#### Expose multisync kernel interface to the driver:
- drm-uapi/v3d: extend interface for multiple semaphores support
- v3dv: check multiple semaphores capability

Basically, they imported drm v3d interface defined in the kernel and verify if
the version of the kernel-driver exposes the multisync capability.

#### Handle multiple wait semaphores for CL, CSD and TFU submissions:
- v3dv: enable multiple semaphores on cl submission
- v3dv: enable multiple semaphores for tfu job
- v3dv: enable multiple semaphores for csd job

Created all mechanisms to set arrays of wait and signal semaphores, check the
conditions that define the wait\_stage and wrap them in a multisync extension.
Also passes multisync extension via generic extension to the kernel driver. At
this point we are only changing the submission design to consider multiple wait
semaphores. Before supporting multisync, v3dv waits for the last job submitted
being signalled when at least one wait semaphore was defined, even when
serialization wasn't required. After these changes, jobs to any submission
queues handle actual wait semaphores. Next, we enable the use of multiple
signal semaphores too.

#### Handle multiple signal semaphores
- v3dv: enable GPU jobs to signal multiple semaphores

It extends the ability of GPU jobs to handle multiple signal semaphores, but at
this point no GPU job is actually in charge of signalling them. From this
enablamente, we started to rework part of the code that track CPU and GPU job
completions. It envolves verifying the GPU status and also threads spawned by
Event jobs.

#### Rework the QueueWaitIdle mechanism to track the syncobj of the last job submitted in each queue.
- v3dv: track submitted jobs by GPU queue type

As we had only single in/out syncobj interfaces for semaphores, we used a
single `last_job_sync` to syncronize job dependencies of previous submission.
Although in the kernel space the DRM scheduler guarantees the order to start to
execute a job in the same queue, the order of completion isn't predictable. On
the other hand, we still need to use syncobjs to follow job completion, since
we have events threads in the CPU side. Therefore, a more accurate
implementation requires `last_job` syncobjs for each engine: CL, TFU and CSD. We
also needed to keep the driver working on previous versions of v3d
kernel-driver with single semaphores, then we keep tracking an ANY
`last_job_sync` to preserve the previous implementation. 

#### Rework synchronization and submission design to let the jobs handle wait and signal semaphores.

With multiple semaphores support, the conditions for waiting and signalling
semaphores changed accordingly to characteristics of each GPU job (CL, CSD,
TFU) and also CPU job peculiarities and restrictions (Events, CSD indirect,
etc.). In this sense, we redesigned V3DV semaphores handling and job
submissions for command buffer batches in
[vkQueueSubmit](https://www.khronos.org/registry/vulkan/specs/1.3-extensions/man/html/vkQueueSubmit.html).

We scrutinised possible scenarios on submitting command buffer batches, to
carefully change the original implementation. It resulted in three commits
more:

- v3dv: handle wait semaphores in the first job by queue

Foreach command buffer, we keep track of whether we have submitted a job to
each GPU queue (CSD, TFU, CL) and a CPU job. For this, we use syncobjs to track
the last job submitted to each GPU queue and a flag that indicates if this
represent the beginning of a command buffer.

The first GPU job submitted to a GPU queue in a command buffer should wait on
wait semaphores. The first CPU job submitted in a command buffer should call
v3dv\_QueueWaitIdle() to do the waiting and ignore semaphores (because it is
waiting for everything).

If the job is not the first, but has the serialize flag set, it should wait on
the completion of all last job submitted to any GPU queue before running. In
practice, it means using syncobjs to track the last job submitted by queue and
add these syncobjs as job dependencies of this serialized job.

- v3dv: process signal semaphores in the very last job

If this job is the last job of a command buffer batch, it may be used to signal
semaphores if this command buffer batch has only one type of GPU job (because
we have guarantees of execution ordering). Otherwise, we emit a no-op job just
to signal semaphores. It waits on completion of all last job submitted to any
GPU queue and then signal semaphores. *Note: at some point, we changed this
approach to correct deal with ordering changes caused by event threads.
Whenever we have a event job in the command buffer, we cannot use the last job
in the last command buffer. We have to wait all event threads complete to
signal*

- v3dv: signal fence when all submitted jobs complete execution

After submitting all command buffers, we emit a no-op job that wait on all last
jobs by queue completion and signal fence. *Note: at some point, we changed
this approach to correct deal with ordering changes caused by event threads, as
mentioned before.*

### Additional fixes and improvements for multisync implementation

With many changes and many rounds of reviews, the patchset was merged. After
more validations and code review, we polished and fixed the implementation
together external contributions:
- v3dv: fix double free error when releasing `sems_info` resources
- v3dv: enable multisync in the simulator
- v3dv: Add missing unlocks on errors.
- v3dv: don't submit noop job if there is nothing to wait on or signal
- v3dv: fix temporary imports of semaphores and fences with multisync
- v3dv: don't signal semaphores/fences from a wait thread
- v3dv: fix semaphore wait from CPU job
- v3dv: Stop leaking in/out fences with multisync

Also, Iago Toral and Alejandro PiÃ±eiro have been working on implementing new
features that depended on multisync capabilities:

- [v3dv: expose support for semaphore imports](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/15342)
> This was waiting for multisync support in the v3d kernel, which is already available. Exposing this feature however enabled a few more CTS tests that exposed pre-existing bugs in the user-space driver so we fix those here before exposing the feature.

- [v3dv: Port to the common synchronization and submit framework - WIP](https://gitlab.freedesktop.org/mesa/mesa/-/issues/5638)
> This should give you emulated timeline semaphores for free and kernel-assisted sharable timeline semaphores for cheap once you have the kernel interface wired in.

### Final considerations

We use a set of games to ensure new implementation doesn't cause regressions.
For performance assesment, we reproduced scenes we have recorded with
[GFXReconstruct](https://github.com/LunarG/gfxreconstruct). In general, we
didn't see any significant change on performance, neither for better nor for
worse, but vkQuake showed an improvement of ~15% from our recordings. 
